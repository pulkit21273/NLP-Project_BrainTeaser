{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8215488,"sourceType":"datasetVersion","datasetId":4869392}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Model, T5EncoderModel\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split, Dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:20.236399Z","iopub.execute_input":"2024-04-25T14:22:20.236789Z","iopub.status.idle":"2024-04-25T14:22:29.421911Z","shell.execute_reply.started":"2024-04-25T14:22:20.236758Z","shell.execute_reply":"2024-04-25T14:22:29.420996Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:29.423937Z","iopub.execute_input":"2024-04-25T14:22:29.424533Z","iopub.status.idle":"2024-04-25T14:22:29.429169Z","shell.execute_reply.started":"2024-04-25T14:22:29.424497Z","shell.execute_reply":"2024-04-25T14:22:29.428266Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# import sentencepiece","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:29.430219Z","iopub.execute_input":"2024-04-25T14:22:29.430515Z","iopub.status.idle":"2024-04-25T14:22:29.440257Z","shell.execute_reply.started":"2024-04-25T14:22:29.430458Z","shell.execute_reply":"2024-04-25T14:22:29.439292Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:29.442395Z","iopub.execute_input":"2024-04-25T14:22:29.442722Z","iopub.status.idle":"2024-04-25T14:22:29.474620Z","shell.execute_reply.started":"2024-04-25T14:22:29.442690Z","shell.execute_reply":"2024-04-25T14:22:29.473868Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:29.475926Z","iopub.execute_input":"2024-04-25T14:22:29.476204Z","iopub.status.idle":"2024-04-25T14:22:29.495140Z","shell.execute_reply.started":"2024-04-25T14:22:29.476181Z","shell.execute_reply":"2024-04-25T14:22:29.494189Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"model = T5EncoderModel.from_pretrained('google/flan-t5-small').to(device)\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:29.496328Z","iopub.execute_input":"2024-04-25T14:22:29.496701Z","iopub.status.idle":"2024-04-25T14:22:34.382550Z","shell.execute_reply.started":"2024-04-25T14:22:29.496669Z","shell.execute_reply":"2024-04-25T14:22:34.381444Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94b056368d7545489f9d793c18c690d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5d8589de8494407a405cc3fed48a16f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26fdf332769a4d52887581d397e173c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43e73480052043beb2cd21cdc789b85a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"470f6bfed0d14eb6854e43beacf4626e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c674c6d952724a6593362cfaa43b24e1"}},"metadata":{}}]},{"cell_type":"code","source":"data = np.load('/kaggle/input/nlpproject/SP-train.npy', allow_pickle = True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.383703Z","iopub.execute_input":"2024-04-25T14:22:34.383996Z","iopub.status.idle":"2024-04-25T14:22:34.396209Z","shell.execute_reply.started":"2024-04-25T14:22:34.383971Z","shell.execute_reply":"2024-04-25T14:22:34.395400Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.397233Z","iopub.execute_input":"2024-04-25T14:22:34.397534Z","iopub.status.idle":"2024-04-25T14:22:34.528882Z","shell.execute_reply.started":"2024-04-25T14:22:34.397505Z","shell.execute_reply":"2024-04-25T14:22:34.527809Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'id': 'SP-0_CR',\n 'question': 'A chess team has five players, and each player has one coach. But there are only six participants in the team. How is that possible?',\n 'answer': 'Each player shares the same coach.',\n 'distractor1': 'Some coaches get a raise.',\n 'distractor2': 'Some players are backups and not allowed to play.',\n 'distractor(unsure)': 'None of above.',\n 'label': 0,\n 'choice_list': ['Each player shares the same coach.',\n  'Some players are backups and not allowed to play.',\n  'Some coaches get a raise.',\n  'None of above.'],\n 'choice_order': [0, 2, 1, 3]}"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.530038Z","iopub.execute_input":"2024-04-25T14:22:34.530347Z","iopub.status.idle":"2024-04-25T14:22:34.539751Z","shell.execute_reply.started":"2024-04-25T14:22:34.530321Z","shell.execute_reply":"2024-04-25T14:22:34.538857Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_train = data.iloc[:405,:]\ndf_dev = data.iloc[405:456,:]\ndf_test = data.iloc[456:507,:]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.544000Z","iopub.execute_input":"2024-04-25T14:22:34.544373Z","iopub.status.idle":"2024-04-25T14:22:34.550782Z","shell.execute_reply.started":"2024-04-25T14:22:34.544348Z","shell.execute_reply":"2024-04-25T14:22:34.549797Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_dev.reset_index(drop=True, inplace=True)\ndf_test.reset_index(drop=True, inplace=True)\ndf_train.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.551856Z","iopub.execute_input":"2024-04-25T14:22:34.552186Z","iopub.status.idle":"2024-04-25T14:22:34.562344Z","shell.execute_reply.started":"2024-04-25T14:22:34.552162Z","shell.execute_reply":"2024-04-25T14:22:34.561371Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(len(data)) # 405 51 51","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.563395Z","iopub.execute_input":"2024-04-25T14:22:34.563715Z","iopub.status.idle":"2024-04-25T14:22:34.573439Z","shell.execute_reply.started":"2024-04-25T14:22:34.563692Z","shell.execute_reply":"2024-04-25T14:22:34.572538Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"507\n","output_type":"stream"}]},{"cell_type":"code","source":"len(df_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.574528Z","iopub.execute_input":"2024-04-25T14:22:34.574813Z","iopub.status.idle":"2024-04-25T14:22:34.586057Z","shell.execute_reply.started":"2024-04-25T14:22:34.574789Z","shell.execute_reply":"2024-04-25T14:22:34.585179Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"405"},"metadata":{}}]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.587036Z","iopub.execute_input":"2024-04-25T14:22:34.587309Z","iopub.status.idle":"2024-04-25T14:22:34.616423Z","shell.execute_reply.started":"2024-04-25T14:22:34.587287Z","shell.execute_reply":"2024-04-25T14:22:34.615625Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                     0\n0    {'id': 'SP-0', 'question': 'Mr. and Mrs. Musta...\n1    {'id': 'SP-0_SR', 'question': 'The six daughte...\n2    {'id': 'SP-0_CR', 'question': 'A chess team ha...\n3    {'id': 'SP-1', 'question': 'A woman shoots her...\n4    {'id': 'SP-1_SR', 'question': 'An individual s...\n..                                                 ...\n400  {'id': 'SP-162_SR', 'question': 'What is the m...\n401  {'id': 'SP-162_CR', 'question': 'There were 10...\n402  {'id': 'SP-163', 'question': 'Thomas was caugh...\n403  {'id': 'SP-163_SR', 'question': 'Despite being...\n404  {'id': 'SP-163_CR', 'question': 'There was a g...\n\n[405 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'id': 'SP-0', 'question': 'Mr. and Mrs. Musta...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'id': 'SP-0_SR', 'question': 'The six daughte...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'id': 'SP-0_CR', 'question': 'A chess team ha...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'id': 'SP-1', 'question': 'A woman shoots her...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'id': 'SP-1_SR', 'question': 'An individual s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>400</th>\n      <td>{'id': 'SP-162_SR', 'question': 'What is the m...</td>\n    </tr>\n    <tr>\n      <th>401</th>\n      <td>{'id': 'SP-162_CR', 'question': 'There were 10...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>{'id': 'SP-163', 'question': 'Thomas was caugh...</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>{'id': 'SP-163_SR', 'question': 'Despite being...</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>{'id': 'SP-163_CR', 'question': 'There was a g...</td>\n    </tr>\n  </tbody>\n</table>\n<p>405 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for i in df_train.columns:\n    print(i)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.617358Z","iopub.execute_input":"2024-04-25T14:22:34.617742Z","iopub.status.idle":"2024-04-25T14:22:34.622160Z","shell.execute_reply.started":"2024-04-25T14:22:34.617718Z","shell.execute_reply":"2024-04-25T14:22:34.621220Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.623285Z","iopub.execute_input":"2024-04-25T14:22:34.623590Z","iopub.status.idle":"2024-04-25T14:22:34.667159Z","shell.execute_reply.started":"2024-04-25T14:22:34.623566Z","shell.execute_reply":"2024-04-25T14:22:34.666259Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                        0\ncount                                                 405\nunique                                                405\ntop     {'id': 'SP-163_CR', 'question': 'There was a g...\nfreq                                                    1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>405</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>405</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>{'id': 'SP-163_CR', 'question': 'There was a g...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# correct = []\n# list1 = []\n# list2 = []\n# list3 = []\n\n# for i in data:\n#     corr_index = i['label']\n#     count = 0\n    \n#     for j in range(len(i['choice_list'])):\n#         if j == corr_index:\n#             correct.append(i['question']+\" \"+i['choice_list'][corr_index])\n#         else:\n#             if count == 0:\n#                 list1.append(i['question']+\" \"+i['choice_list'][j])\n#                 count+=1\n#             elif count == 1:\n#                 list2.append(i['question']+\" \"+i['choice_list'][j])\n#                 count+=1\n#             elif count == 2:\n#                 list3.append(i['question']+\" \"+i['choice_list'][j])\n#                 count+=1\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.668316Z","iopub.execute_input":"2024-04-25T14:22:34.668608Z","iopub.status.idle":"2024-04-25T14:22:34.673294Z","shell.execute_reply.started":"2024-04-25T14:22:34.668582Z","shell.execute_reply":"2024-04-25T14:22:34.672186Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# correct_embeddings = tokenizer(correct, max_length = 128, padding=True, truncation=True, return_tensors = 'pt')\n# list1_embeddings = tokenizer(list1, max_length = 128, padding=True, truncation=True, return_tensors = 'pt')\n# list2_embeddings = tokenizer(list2, max_length = 128, padding=True, truncation=True, return_tensors = 'pt')\n# list3_embeddings = tokenizer(list3, max_length = 128, padding=True, truncation=True, return_tensors = 'pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.674507Z","iopub.execute_input":"2024-04-25T14:22:34.674794Z","iopub.status.idle":"2024-04-25T14:22:34.683869Z","shell.execute_reply.started":"2024-04-25T14:22:34.674766Z","shell.execute_reply":"2024-04-25T14:22:34.683118Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# len(correct_embeddings[0]), len(list1_embeddings[0]), len(list2_embeddings[0]), len(list3_embeddings[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.685016Z","iopub.execute_input":"2024-04-25T14:22:34.685253Z","iopub.status.idle":"2024-04-25T14:22:34.698309Z","shell.execute_reply.started":"2024-04-25T14:22:34.685232Z","shell.execute_reply":"2024-04-25T14:22:34.697525Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class TaskDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        entry = self.data[0][idx]\n        question = entry['question']\n        choices = entry['choice_list']\n        label = entry['label']\n        choice_order = entry['choice_order']\n        correct_index = choice_order.index(label)\n\n        tokenized_choices = [self.tokenizer.encode_plus(  question + \"[SEP]\" + choice, add_special_tokens = True, max_length = 128, truncation=True, padding='max_length', return_tensors = 'pt') for choice in choices]\n\n        input_ids = torch.cat([choice['input_ids'].unsqueeze(0) for choice in tokenized_choices],dim=0)\n        attention_mask = torch.cat([choice['attention_mask'].unsqueeze(0) for choice in tokenized_choices],dim=0)\n        labels = torch.zeros(len(choices), dtype=torch.long)\n        labels[label] = 1\n\n        input_ids_m = []\n        attention_mask_m = []\n        labels_m = []\n\n        for i in choice_order:\n            input_ids_m.append(input_ids[i])\n            attention_mask_m.append(attention_mask[i])\n            labels_m.append(labels[i])\n            \n\n        return input_ids_m, attention_mask_m, torch.tensor(labels_m)\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.699422Z","iopub.execute_input":"2024-04-25T14:22:34.699718Z","iopub.status.idle":"2024-04-25T14:22:34.711316Z","shell.execute_reply.started":"2024-04-25T14:22:34.699695Z","shell.execute_reply":"2024-04-25T14:22:34.710445Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class TaskModel(nn.Module):\n    def __init__(self, model):\n        super(TaskModel, self).__init__()\n        self.t5 = model\n        # self.classifier = nn.Linear(self.t5.config.d_model, 1)\n        self.classifier = nn.Sequential(\n            nn.Linear(self.t5.config.d_model, 768), \n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(768, 1)\n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        output = self.t5(input_ids = input_ids, attention_mask = attention_mask, return_dict = True)\n        last_hidden_states = output.last_hidden_state[:, 0, :]\n        logits = self.classifier(last_hidden_states)\n        return logits\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.712438Z","iopub.execute_input":"2024-04-25T14:22:34.713264Z","iopub.status.idle":"2024-04-25T14:22:34.721358Z","shell.execute_reply.started":"2024-04-25T14:22:34.713231Z","shell.execute_reply":"2024-04-25T14:22:34.720610Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_dataset = TaskDataset(df_train, tokenizer)\nval_dataset = TaskDataset(df_dev, tokenizer)\ntest_dataset = TaskDataset(df_test, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.722447Z","iopub.execute_input":"2024-04-25T14:22:34.722787Z","iopub.status.idle":"2024-04-25T14:22:34.734713Z","shell.execute_reply.started":"2024-04-25T14:22:34.722763Z","shell.execute_reply":"2024-04-25T14:22:34.733884Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\nvalidation_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.735786Z","iopub.execute_input":"2024-04-25T14:22:34.736055Z","iopub.status.idle":"2024-04-25T14:22:34.745231Z","shell.execute_reply.started":"2024-04-25T14:22:34.736030Z","shell.execute_reply":"2024-04-25T14:22:34.744457Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_dataset[3]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.746378Z","iopub.execute_input":"2024-04-25T14:22:34.746962Z","iopub.status.idle":"2024-04-25T14:22:34.778708Z","shell.execute_reply.started":"2024-04-25T14:22:34.746930Z","shell.execute_reply":"2024-04-25T14:22:34.777801Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"([tensor([[   71,  2335,  4279,     7,   160,  2553,     5,    37,    29,   255,\n            4532,   376, 22409,    21,   147,   305,   676,     5,  4213,     6,\n             255,  5168,     7,   376,     5,   299,   305,   676,   865,     6,\n              79,   321,   281,    91,    11,   777,     3,     9,  1627,  2634,\n             544,     5,   571,    54,    48,    36,    58,  6306,   134,  8569,\n             908,   634,  2335,  2347,     3,     9,   126,  2397,     5,     1,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0]]),\n  tensor([[   71,  2335,  4279,     7,   160,  2553,     5,    37,    29,   255,\n            4532,   376, 22409,    21,   147,   305,   676,     5,  4213,     6,\n             255,  5168,     7,   376,     5,   299,   305,   676,   865,     6,\n              79,   321,   281,    91,    11,   777,     3,     9,  1627,  2634,\n             544,     5,   571,    54,    48,    36,    58,  6306,   134,  8569,\n             908,   634,  2335,    47,     3,     9,  9050,     5,   451,  2538,\n               3,     9,  1554,    13,   160,  2553,     6,  1597,    34,     6,\n              11,     3,  6668,    34,    95,    12,  2192,     5,     1,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0]]),\n  tensor([[   71,  2335,  4279,     7,   160,  2553,     5,    37,    29,   255,\n            4532,   376, 22409,    21,   147,   305,   676,     5,  4213,     6,\n             255,  5168,     7,   376,     5,   299,   305,   676,   865,     6,\n              79,   321,   281,    91,    11,   777,     3,     9,  1627,  2634,\n             544,     5,   571,    54,    48,    36,    58,  6306,   134,  8569,\n             908,   634,  2335,  2347, 10195,    21,  7738,   227,  2634,     5,\n               1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0]]),\n  tensor([[   71,  2335,  4279,     7,   160,  2553,     5,    37,    29,   255,\n            4532,   376, 22409,    21,   147,   305,   676,     5,  4213,     6,\n             255,  5168,     7,   376,     5,   299,   305,   676,   865,     6,\n              79,   321,   281,    91,    11,   777,     3,     9,  1627,  2634,\n             544,     5,   571,    54,    48,    36,    58,  6306,   134,  8569,\n             908,   567,   782,    13,   756,     5,     1,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0,     0,     0,     0]])],\n [tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0]]),\n  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0]]),\n  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0]]),\n  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0]])],\n tensor([0, 1, 0, 0]))"},"metadata":{}}]},{"cell_type":"code","source":"Modelarch = TaskModel(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.780027Z","iopub.execute_input":"2024-04-25T14:22:34.780383Z","iopub.status.idle":"2024-04-25T14:22:34.789387Z","shell.execute_reply.started":"2024-04-25T14:22:34.780351Z","shell.execute_reply":"2024-04-25T14:22:34.788445Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# from torch.utils.data import DataLoader, random_split\n\n# train_size = int(0.8 * len(traindataset))  \n# validation_size = len(traindataset) - train_size  \n\n# train_dataset, validation_dataset = random_split(traindataset, [train_size, validation_size])\n\n# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n# validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.790696Z","iopub.execute_input":"2024-04-25T14:22:34.791375Z","iopub.status.idle":"2024-04-25T14:22:34.796026Z","shell.execute_reply.started":"2024-04-25T14:22:34.791342Z","shell.execute_reply":"2024-04-25T14:22:34.795040Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.797070Z","iopub.execute_input":"2024-04-25T14:22:34.797338Z","iopub.status.idle":"2024-04-25T14:22:34.807120Z","shell.execute_reply.started":"2024-04-25T14:22:34.797316Z","shell.execute_reply":"2024-04-25T14:22:34.806347Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# logits.squeeze(), labels","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.812273Z","iopub.execute_input":"2024-04-25T14:22:34.812581Z","iopub.status.idle":"2024-04-25T14:22:34.816455Z","shell.execute_reply.started":"2024-04-25T14:22:34.812559Z","shell.execute_reply":"2024-04-25T14:22:34.815618Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Training loop\n# model.train()\nModelarch.to(device)\nfor epoch in range(10):  # Number of epochs\n    total_loss = 0\n    Modelarch.train()\n    \n    for input_ids, attention_mask, labels in train_loader:\n        optimizer.zero_grad()\n        logits = []\n        for i,j in zip(input_ids, attention_mask):\n            #print(i.squeeze(0).shape,j.squeeze(0).shape)\n            logits.append(Modelarch(i.squeeze(0).to(device),j.squeeze(0).to(device)))\n        logits = torch.stack(logits).squeeze()\n        labels = labels.float().squeeze(0).to(device)\n        # print(logits)\n        # print(labels)\n        # logits = Modelarch(input_ids, attention_mask)\n        loss = criterion(logits, labels.float())\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        \n    loss = total_loss/len(train_loader)\n    print(f'Epoch {epoch+1}, Loss: {loss}')\n    \n    Modelarch.eval()\n    all_predictions = []\n    all_labels = []\n    total_loss = 0\n    \n    for input_ids, attention_mask, labels in validation_loader:\n            optimizer.zero_grad()\n            logits = []\n            for i,j in zip(input_ids, attention_mask):\n                #print(i.squeeze(0).shape,j.squeeze(0).shape)\n                logits.append(Modelarch(i.squeeze(0).to(device),j.squeeze(0).to(device)))\n            logits = torch.stack(logits).squeeze()\n            labels = labels.float().squeeze(0).to(device)\n            # print(logits)\n            probabilities = F.softmax(logits, dim=0)\n            # Get the predicted class index\n            predictions = torch.argmax(probabilities, dim=0)\n            predictions = F.one_hot(predictions, num_classes=4) \n            # print(predictions)\n            # print(labels)\n            # logits = Modelarch(input_ids, attention_mask)\n            loss = criterion(logits, labels.float())\n            total_loss += loss.item()\n            all_predictions.extend(predictions.tolist())\n            all_labels.extend(labels.squeeze(0).tolist())\n\n    # Compute accuracy and F1 score\n    accuracy = accuracy_score(all_labels, all_predictions)\n    f1 = f1_score(all_labels, all_predictions, average='macro')\n    val_loss = total_loss / len(validation_loader)\n    \n    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Loss : {val_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:22:34.817608Z","iopub.execute_input":"2024-04-25T14:22:34.817927Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.6389157368813032\nAccuracy: 0.7549019607843137, F1 Score: 0.673202614379085, Loss : 0.6034411121817196\nEpoch 2, Loss: 0.5953371986930753\nAccuracy: 0.7745098039215687, F1 Score: 0.6993464052287581, Loss : 0.5844644495085174\nEpoch 3, Loss: 0.5826148908815266\nAccuracy: 0.7156862745098039, F1 Score: 0.6209150326797386, Loss : 0.5779303733040305\nEpoch 4, Loss: 0.576270506411423\nAccuracy: 0.7843137254901961, F1 Score: 0.7124183006535947, Loss : 0.5731305386505875\nEpoch 5, Loss: 0.5619251700831048\nAccuracy: 0.8235294117647058, F1 Score: 0.7647058823529411, Loss : 0.5374209810705746\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Training loop\n# # model.train()\n# for epoch in range(5):  # Number of epochs\n#     total_loss = 0\n#     Modelarch.train()\n    \n#     for input_ids, attention_mask, labels in train_loader:\n#         optimizer.zero_grad()\n#         logits = []\n#         for i,j in zip(input_ids, attention_mask):\n#             #print(i.squeeze(1).shape,j.squeeze(1).shape)\n#             logits.append(Modelarch(i.squeeze(1),j.squeeze(1)))\n#         #print(logits)\n#         logits = torch.stack(logits, dim=2).squeeze(1)\n#         labels = labels.float().squeeze(0)\n#         #print(logits.shape)\n#         #print(labels.shape)\n        \n#         # logits = Modelarch(input_ids, attention_mask)\n#         loss = criterion(logits, labels.float())\n#         loss.backward()\n#         optimizer.step()\n#         total_loss += loss.item()\n        \n#     loss = total_loss/len(train_loader)\n#     print(f'Epoch {epoch+1}, Loss: {loss}')\n    \n#     Modelarch.eval()\n#     all_predictions = []\n#     all_labels = []\n#     total_loss = 0\n    \n#     for input_ids, attention_mask, labels in validation_loader:\n#             optimizer.zero_grad()\n#             logits = []\n#             for i,j in zip(input_ids, attention_mask):\n#                 # print(i)\n#                 # print(i.squeeze(1).shape , j.squeeze(1).shape)\n#                 logits.append(Modelarch(i.squeeze(1),j.squeeze(1)))\n#             logits = torch.stack(logits, dim=2).squeeze(1)\n#             labels = labels.float().squeeze(0)\n#             # print(logits)\n#             probabilities = F.softmax(logits, dim=0)\n#             # Get the predicted class index\n#             predictions = torch.argmax(probabilities, dim=1)\n#             predictions = F.one_hot(predictions, num_classes=4) \n#             # print(predictions)\n#             # print(labels)\n#             # logits = Modelarch(input_ids, attention_mask)\n#             loss = criterion(logits, labels.float())\n#             total_loss += loss.item()\n#             all_predictions.extend(predictions.tolist())\n#             all_labels.extend(labels.squeeze(0).tolist())\n\n#     # Compute accuracy and F1 score\n#     accuracy = accuracy_score(all_labels, all_predictions)\n#     f1 = f1_score(all_labels, all_predictions, average='macro')\n#     val_loss = total_loss / len(validation_loader)\n    \n#     print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Loss : {val_loss}\")\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nall_predictions = []\nall_labels = []\ntotal_loss = 0\nfor input_ids, attention_mask, labels in test_loader:\n        optimizer.zero_grad()\n        logits = []\n        for i,j in zip(input_ids, attention_mask):\n            #print(i.squeeze(0).shape,j.squeeze(0).shape)\n            logits.append(Modelarch(i.squeeze(1),j.squeeze(1)))\n        logits = torch.stack(logits, dim=2).squeeze(1)\n        labels = labels.float().squeeze(0)\n        # print(logits)\n        probabilities = F.softmax(logits, dim=1)\n        # Get the predicted class index\n        predictions = torch.argmax(probabilities, dim=1)\n        predictions = F.one_hot(predictions, num_classes=4)\n    \n        # for i in range(len(labels)):\n        #     if labels[i] == 1:\n        #         label = i\n        # for i in range(len(predictions)):\n        #     if predictions[i] == 1:\n        #         prediction = i\n        # print(label, prediction)\n        # print(input_ids[label])\n        # print(type(label))\n        # print(type(input_ids[label]))\n    \n        # print(\"correct: \"+tokenizer.decode(input_ids[label].squeeze(), skip_special_tokens = True))\n        # print(\"predicted: \"+tokenizer.decode(input_ids[prediction].squeeze(), skip_special_tokens = True))\n    \n        # print(predictions)\n        # print(labels)\n        # logits = Modelarch(input_ids, attention_mask)\n        loss = criterion(logits, labels.float())\n        all_predictions.extend(predictions.tolist())\n        all_labels.extend(labels.squeeze(0).tolist())\n        total_loss += loss.item()\n    \n# Compute accuracy and F1 score\naccuracy = accuracy_score(all_labels, all_predictions)\nf1 = f1_score(all_labels, all_predictions, average='macro')\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"F1 Score: {f1}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(Modelarch, './Model2_6_45.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}