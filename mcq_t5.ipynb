{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8228144,"sourceType":"datasetVersion","datasetId":4879122}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Model, T5EncoderModel\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split, Dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:38.684065Z","iopub.execute_input":"2024-04-25T18:01:38.684475Z","iopub.status.idle":"2024-04-25T18:01:47.833359Z","shell.execute_reply.started":"2024-04-25T18:01:38.684431Z","shell.execute_reply":"2024-04-25T18:01:47.832367Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:47.835484Z","iopub.execute_input":"2024-04-25T18:01:47.836089Z","iopub.status.idle":"2024-04-25T18:01:47.868557Z","shell.execute_reply.started":"2024-04-25T18:01:47.836052Z","shell.execute_reply":"2024-04-25T18:01:47.867395Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"model = T5EncoderModel.from_pretrained('google-t5/t5-small').to(device)\ntokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:47.869638Z","iopub.execute_input":"2024-04-25T18:01:47.869931Z","iopub.status.idle":"2024-04-25T18:01:50.754170Z","shell.execute_reply.started":"2024-04-25T18:01:47.869905Z","shell.execute_reply":"2024-04-25T18:01:50.753251Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08dea6b355c04119b2be2e2184c9254b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a7a62678a0547bd915eb904c4459f92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd9300e63006453ba15f935379c1c489"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32fd389489574eb29138fe401a277850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae6ed8ed7024427698a5ebc5259f38f3"}},"metadata":{}}]},{"cell_type":"code","source":"data = np.load('/kaggle/input/nlpproject/SP-train.npy', allow_pickle = True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.756520Z","iopub.execute_input":"2024-04-25T18:01:50.756848Z","iopub.status.idle":"2024-04-25T18:01:50.771245Z","shell.execute_reply.started":"2024-04-25T18:01:50.756820Z","shell.execute_reply":"2024-04-25T18:01:50.770180Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.772660Z","iopub.execute_input":"2024-04-25T18:01:50.772984Z","iopub.status.idle":"2024-04-25T18:01:50.780986Z","shell.execute_reply.started":"2024-04-25T18:01:50.772957Z","shell.execute_reply":"2024-04-25T18:01:50.779989Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train = data.iloc[:405,:]\ndf_dev = data.iloc[405:456,:]\ndf_test = data.iloc[456:507,:]\ndf_dev.reset_index(drop=True, inplace=True)\ndf_test.reset_index(drop=True, inplace=True)\ndf_train.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.782474Z","iopub.execute_input":"2024-04-25T18:01:50.782825Z","iopub.status.idle":"2024-04-25T18:01:50.792777Z","shell.execute_reply.started":"2024-04-25T18:01:50.782797Z","shell.execute_reply":"2024-04-25T18:01:50.791736Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TaskDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        entry = self.data[0][idx]\n        question = entry['question']\n        choices = entry['choice_list']\n        label = entry['label']\n        choice_order = entry['choice_order']\n        correct_index = choice_order.index(label)\n\n        tokenized_choices = [self.tokenizer.encode_plus(  question + \"[SEP]\" + choice, add_special_tokens = True, max_length = 128, truncation=True, padding='max_length', return_tensors = 'pt') for choice in choices]\n\n        input_ids = torch.cat([choice['input_ids'].unsqueeze(0) for choice in tokenized_choices],dim=0)\n        attention_mask = torch.cat([choice['attention_mask'].unsqueeze(0) for choice in tokenized_choices],dim=0)\n        labels = torch.zeros(len(choices), dtype=torch.long)\n        labels[label] = 1\n\n        input_ids_m = []\n        attention_mask_m = []\n        labels_m = []\n\n        for i in choice_order:\n            input_ids_m.append(input_ids[i])\n            attention_mask_m.append(attention_mask[i])\n            labels_m.append(labels[i])\n            \n\n        return input_ids_m, attention_mask_m, torch.tensor(labels_m)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.793902Z","iopub.execute_input":"2024-04-25T18:01:50.794217Z","iopub.status.idle":"2024-04-25T18:01:50.806530Z","shell.execute_reply.started":"2024-04-25T18:01:50.794188Z","shell.execute_reply":"2024-04-25T18:01:50.805508Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class TaskModel(nn.Module):\n    def __init__(self, model):\n        super(TaskModel, self).__init__()\n        self.t5 = model\n        # self.classifier = nn.Linear(self.t5.config.d_model, 1)\n        self.classifier = nn.Sequential(\n            nn.Linear(self.t5.config.d_model, 768), \n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(768, 1)\n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        output = self.t5(input_ids = input_ids, attention_mask = attention_mask, return_dict = True)\n        last_hidden_states = output.last_hidden_state[:, 0, :]\n        logits = self.classifier(last_hidden_states)\n        return logits\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.807712Z","iopub.execute_input":"2024-04-25T18:01:50.808020Z","iopub.status.idle":"2024-04-25T18:01:50.823701Z","shell.execute_reply.started":"2024-04-25T18:01:50.807994Z","shell.execute_reply":"2024-04-25T18:01:50.822484Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = TaskDataset(df_train, tokenizer)\nval_dataset = TaskDataset(df_dev, tokenizer)\ntest_dataset = TaskDataset(df_test, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.824981Z","iopub.execute_input":"2024-04-25T18:01:50.825386Z","iopub.status.idle":"2024-04-25T18:01:50.834881Z","shell.execute_reply.started":"2024-04-25T18:01:50.825358Z","shell.execute_reply":"2024-04-25T18:01:50.833903Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\nvalidation_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.838089Z","iopub.execute_input":"2024-04-25T18:01:50.838452Z","iopub.status.idle":"2024-04-25T18:01:50.850245Z","shell.execute_reply.started":"2024-04-25T18:01:50.838413Z","shell.execute_reply":"2024-04-25T18:01:50.849256Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"Modelarch = TaskModel(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.851408Z","iopub.execute_input":"2024-04-25T18:01:50.851716Z","iopub.status.idle":"2024-04-25T18:01:50.867263Z","shell.execute_reply.started":"2024-04-25T18:01:50.851691Z","shell.execute_reply":"2024-04-25T18:01:50.866367Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.868382Z","iopub.execute_input":"2024-04-25T18:01:50.869721Z","iopub.status.idle":"2024-04-25T18:01:50.875903Z","shell.execute_reply.started":"2024-04-25T18:01:50.869690Z","shell.execute_reply":"2024-04-25T18:01:50.874950Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Training loop\n# model.train()\nModelarch.to(device)\nfor epoch in range(10):  # Number of epochs\n    total_loss = 0\n    Modelarch.train()\n    \n    for input_ids, attention_mask, labels in train_loader:\n        optimizer.zero_grad()\n        logits = []\n        for i,j in zip(input_ids, attention_mask):\n            #print(i.squeeze(0).shape,j.squeeze(0).shape)\n            logits.append(Modelarch(i.squeeze(0).to(device),j.squeeze(0).to(device)))\n        logits = torch.stack(logits).squeeze()\n        labels = labels.float().squeeze(0).to(device)\n        # print(logits)\n        # print(labels)\n        # logits = Modelarch(input_ids, attention_mask)\n        loss = criterion(logits, labels.float())\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        \n    loss = total_loss/len(train_loader)\n    print(f'Epoch {epoch+1}, Loss: {loss}')\n    \n    Modelarch.eval()\n    all_predictions = []\n    all_labels = []\n    total_loss = 0\n    \n    for input_ids, attention_mask, labels in validation_loader:\n            optimizer.zero_grad()\n            logits = []\n            for i,j in zip(input_ids, attention_mask):\n                #print(i.squeeze(0).shape,j.squeeze(0).shape)\n                logits.append(Modelarch(i.squeeze(0).to(device),j.squeeze(0).to(device)))\n            logits = torch.stack(logits).squeeze()\n            labels = labels.float().squeeze(0).to(device)\n            # print(logits)\n            probabilities = F.softmax(logits, dim=0)\n            # Get the predicted class index\n            predictions = torch.argmax(probabilities, dim=0)\n            predictions = F.one_hot(predictions, num_classes=4) \n            # print(predictions)\n            # print(labels)\n            # logits = Modelarch(input_ids, attention_mask)\n            loss = criterion(logits, labels.float())\n            total_loss += loss.item()\n            all_predictions.extend(predictions.tolist())\n            all_labels.extend(labels.squeeze(0).tolist())\n\n    # Compute accuracy and F1 score\n    accuracy = accuracy_score(all_labels, all_predictions)\n    f1 = f1_score(all_labels, all_predictions, average='macro')\n    val_loss = total_loss / len(validation_loader)\n    \n    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Loss : {val_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:50.877044Z","iopub.execute_input":"2024-04-25T18:01:50.877330Z","iopub.status.idle":"2024-04-25T18:07:34.591597Z","shell.execute_reply.started":"2024-04-25T18:01:50.877306Z","shell.execute_reply":"2024-04-25T18:07:34.590639Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.6394500051015689\nAccuracy: 0.6862745098039216, F1 Score: 0.5816993464052287, Loss : 0.5937266560161815\nEpoch 2, Loss: 0.5857192623762437\nAccuracy: 0.7058823529411765, F1 Score: 0.6078431372549019, Loss : 0.5691428324755501\nEpoch 3, Loss: 0.5710420386290844\nAccuracy: 0.7254901960784313, F1 Score: 0.6339869281045752, Loss : 0.5629155518961888\nEpoch 4, Loss: 0.5655007719993591\nAccuracy: 0.7843137254901961, F1 Score: 0.7124183006535947, Loss : 0.5589232117521996\nEpoch 5, Loss: 0.5555120978826358\nAccuracy: 0.7843137254901961, F1 Score: 0.7124183006535947, Loss : 0.5389237935636558\nEpoch 6, Loss: 0.5246656057275372\nAccuracy: 0.8333333333333334, F1 Score: 0.7777777777777777, Loss : 0.5214376204154071\nEpoch 7, Loss: 0.4786718423719759\nAccuracy: 0.8137254901960784, F1 Score: 0.7516339869281046, Loss : 0.5025270896799424\nEpoch 8, Loss: 0.43843165937765144\nAccuracy: 0.8333333333333334, F1 Score: 0.7777777777777777, Loss : 0.49532198730637045\nEpoch 9, Loss: 0.406305718642694\nAccuracy: 0.7941176470588235, F1 Score: 0.7254901960784315, Loss : 0.4735684371462055\nEpoch 10, Loss: 0.36570695528277647\nAccuracy: 0.7843137254901961, F1 Score: 0.7124183006535947, Loss : 0.4857816859787586\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nall_predictions = []\nall_labels = []\ntotal_loss = 0\nfor input_ids, attention_mask, labels in test_loader:\n        optimizer.zero_grad()\n        logits = []\n        for i,j in zip(input_ids, attention_mask):\n            #print(i.squeeze(0).shape,j.squeeze(0).shape)\n            logits.append(Modelarch(i.squeeze(1).to(device),j.squeeze(1).to(device)))\n        logits = torch.stack(logits, dim=0).squeeze()\n        labels = labels.float().squeeze(0).to(device)\n        # print(logits)\n        probabilities = F.softmax(logits, dim=0)\n        # Get the predicted class index\n        predictions = torch.argmax(probabilities, dim=0)\n        predictions = F.one_hot(predictions, num_classes=4)\n    \n        # for i in range(len(labels)):\n        #     if labels[i] == 1:\n        #         label = i\n        # for i in range(len(predictions)):\n        #     if predictions[i] == 1:\n        #         prediction = i\n        # print(label, prediction)\n        # print(input_ids[label])\n        # print(type(label))\n        # print(type(input_ids[label]))\n    \n        # print(\"correct: \"+tokenizer.decode(input_ids[label].squeeze(), skip_special_tokens = True))\n        # print(\"predicted: \"+tokenizer.decode(input_ids[prediction].squeeze(), skip_special_tokens = True))\n    \n        # print(predictions)\n        # print(labels)\n        # logits = Modelarch(input_ids, attention_mask)\n        loss = criterion(logits, labels.float())\n        all_predictions.extend(predictions.tolist())\n        all_labels.extend(labels.squeeze(0).tolist())\n        total_loss += loss.item()\n    \n# Compute accuracy and F1 score\naccuracy = accuracy_score(all_labels, all_predictions)\nf1 = f1_score(all_labels, all_predictions, average='macro')\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"F1 Score: {f1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:07:34.592742Z","iopub.execute_input":"2024-04-25T18:07:34.593041Z","iopub.status.idle":"2024-04-25T18:07:36.314226Z","shell.execute_reply.started":"2024-04-25T18:07:34.593014Z","shell.execute_reply":"2024-04-25T18:07:36.313027Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Accuracy: 0.7450980392156863\nF1 Score: 0.6601307189542484\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, './model.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:07:36.315809Z","iopub.execute_input":"2024-04-25T18:07:36.316093Z","iopub.status.idle":"2024-04-25T18:07:36.597062Z","shell.execute_reply.started":"2024-04-25T18:07:36.316067Z","shell.execute_reply":"2024-04-25T18:07:36.596175Z"},"trusted":true},"execution_count":15,"outputs":[]}]}